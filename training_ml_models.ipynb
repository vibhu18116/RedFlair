{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import data_scrapping as ds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorisation(train, test):\n",
    "    vect = CountVectorizer()\n",
    "    \n",
    "    new_train = vect.fit_transform(train)\n",
    "    new_test = vect.transform(test)\n",
    "    \n",
    "    pickle.dump(vect, open(\"vector.pickle\", \"wb\"))\n",
    "    pickle.dump(new_train, open(\"train_comment_features.pickle\", \"wb\"))\n",
    "    \n",
    "    return new_train, new_test\n",
    "\n",
    "#     vect = TfidfVectorizer(min_df = 0.1, max_df = 0.3)\n",
    "    \n",
    "#     new_train = vect.fit_transform(train)\n",
    "#     new_test = vect.transform(test)\n",
    "#     return new_train, new_test\n",
    "    \n",
    "#     vect2 = TfidfTransformer()\n",
    "#     train2 = vect2.fit_transform(new_train)\n",
    "#     test2 = vect2.transform(new_test)\n",
    "#     return train2, test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb(x_train, x_test, y_train, y_test):\n",
    "    from xgboost import XGBRegressor, DMatrix, XGBClassifier\n",
    "    \n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(x_train, y_train)\n",
    "    joblib.dump(xgb, \"flair_predictor.joblib\")\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators = 100)\n",
    "    \n",
    "    rfc.fit(x_train, y_train)\n",
    "    y_pred = rfc.predict(x_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    svm = SVC(gamma = 'scale')\n",
    "    \n",
    "    svm.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(x_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return score    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    logreg = LogisticRegression(solver = \"lbfgs\", multi_class = \"auto\", max_iter = 500)\n",
    "    \n",
    "    logreg.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = logreg.predict(x_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train, y_train)\n",
    "    y_pred = nb.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_models(x, y):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 7)\n",
    "    \n",
    "    x_train, x_test = vectorisation(x_train, x_test)\n",
    "    \n",
    "#     multinomial_nb_model = multinomial(x_train, x_test, y_train, y_test)\n",
    "#     print('Multinomial', multinomial_nb_model)\n",
    "#     log_reg = logisticRegression(x_train, x_test, y_train, y_test)\n",
    "#     print(\"Logistic regression\", log_reg)\n",
    "#     svm_model = svm(x_train, x_test, y_train, y_test)\n",
    "#     print('Single Vector Machine', svm_model)\n",
    "#     random_forest = randomForest(x_train, x_test, y_train, y_test)\n",
    "#     print(\"Random Forest Classifier:\", random_forest)\n",
    "    xgb_model = xgb(x_train, x_test, y_train, y_test)\n",
    "    print(\"Extreme Gradient Boosting:\", xgb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    collection_pointer = ds.initialising_mongo()\n",
    "    complete_dataset = pd.DataFrame(list(collection_pointer.find()))\n",
    "    complete_dataset.dropna(inplace = True)\n",
    "    complete_dataset['merged'] = complete_dataset[\"title\"] + complete_dataset[\"url_path\"] + complete_dataset['comments'] + complete_dataset[\"content\"]\n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize_text(text):\n",
    "        return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "    \n",
    "    complete_dataset[\"comments\"] = complete_dataset.comments.apply(lemmatize_text)\n",
    "    complete_dataset[\"title\"] = complete_dataset.title.apply(lemmatize_text)\n",
    "    complete_dataset[\"content\"] = complete_dataset.content.apply(lemmatize_text)\n",
    "    complete_dataset[\"url_path\"] = complete_dataset.url_path.apply(lemmatize_text)\n",
    "    \n",
    "\n",
    "\n",
    "    Y = complete_dataset.flair\n",
    "    x = complete_dataset.drop('flair', axis = 1)\n",
    "    \n",
    "#     print(\"comments as feature\")\n",
    "#     call_models(x.comments, Y)\n",
    "#     print(\"\\ntitle as a feature\")\n",
    "#     call_models(x.title, Y)\n",
    "#     print(\"\\ncontent as a feature\")\n",
    "#     call_models(x.content, Y)\n",
    "#     print(\"\\nurl_path as a feature\")\n",
    "#     call_models(x.url_path, Y)\n",
    "#     print(\"\\nurl_hostname as a feature\")\n",
    "#     call_models(x.url_hostname, Y)\n",
    "    print(\"\\nmerged as a feature\")\n",
    "    call_models(x.merged, Y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "merged as a feature\n",
      "Extreme Gradient Boosting: 0.5913461538461539\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
