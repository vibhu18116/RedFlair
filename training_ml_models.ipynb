{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import data_scrapping as ds\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorisation(train, test):\n",
    "    vect = CountVectorizer()\n",
    "    \n",
    "    new_train = vect.fit_transform(train)\n",
    "    new_test = vect.transform(test)\n",
    "    return new_train, new_test\n",
    "\n",
    "#     vect = TfidfVectorizer(min_df = 0.1, max_df = 0.3)\n",
    "    \n",
    "#     new_train = vect.fit_transform(train)\n",
    "#     new_test = vect.transform(test)\n",
    "#     return new_train, new_test\n",
    "    \n",
    "#     vect2 = TfidfTransformer()\n",
    "#     train2 = vect2.fit_transform(new_train)\n",
    "#     test2 = vect2.transform(new_test)\n",
    "#     return train2, test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb(x_train, x_test, y_train, y_test):\n",
    "    from xgboost import XGBRegressor, DMatrix, XGBClassifier\n",
    "#     data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "    \n",
    "    xgb = XGBClassifier()\n",
    "    xgb.fit(x_train, y_train)\n",
    "    joblib.dump(xgb, \"flair_predictor.joblib\")\n",
    "    y_pred = xgb.predict(x_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(x_train, x_test, y_train, y_test):\n",
    "#     print(y_train)\n",
    "    from sklearn.neural_network import MLPRegressor\n",
    "    d = dict(zip([\"AskIndia\", \"Business/Finance\",\"AMA\", \"Food\", \"Non-Political\", \"Photography\", \"Policy/Economy\", \\\n",
    "                  \"Politics\", \"Science/Technology\", \"Sports\", \"[R]eddiquette\"], range(0,11)))\n",
    "    \n",
    "    yt1 = y_train.map(d, na_action='ignore')\n",
    "    yt2 = y_test.map(d, na_action='ignore')\n",
    "    yt1 = [yt1]\n",
    "    yt2 = [yt2]\n",
    "#     yt1.reshape(-1,1)\n",
    "#     yt2.reshape(-1,1)\n",
    "    mlp = MLPRegressor(max_iter = 500)\n",
    "    mlp.fit([x_train], yt1)\n",
    "    \n",
    "    y_pred = mlp.predict(yt2)\n",
    "    \n",
    "    score = accuracy_score(y_test, yt2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators = 100)\n",
    "    \n",
    "    rfc.fit(x_train, y_train)\n",
    "    y_pred = rfc.predict(x_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.svm import SVC\n",
    "    \n",
    "    svm = SVC(gamma = 'scale')\n",
    "    \n",
    "    svm.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = svm.predict(x_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return score    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(x_train, x_test, y_train, y_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    logreg = LogisticRegression(solver = \"lbfgs\", multi_class = \"auto\", max_iter = 500)\n",
    "    \n",
    "    logreg.fit(x_train, y_train)\n",
    "    \n",
    "    y_pred = logreg.predict(x_test)\n",
    "    \n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    \n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(x_train, y_train)\n",
    "    y_pred = nb.predict(x_test)\n",
    "    score = accuracy_score(y_test, y_pred)\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_models(x, y):\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 7)\n",
    "    \n",
    "    x_train, x_test = vectorisation(x_train, x_test)\n",
    "#     multinomial_nb_model = multinomial(x_train, x_test, y_train, y_test)\n",
    "#     print('Multinomial', multinomial_nb_model)\n",
    "#     log_reg = logisticRegression(x_train, x_test, y_train, y_test)\n",
    "#     print(\"Logistic regression\", log_reg)\n",
    "#     svm_model = svm(x_train, x_test, y_train, y_test)\n",
    "#     print('Single Vector Machine', svm_model)\n",
    "#     random_forest = randomForest(x_train, x_test, y_train, y_test)\n",
    "#     print(\"Random Forest Classifier:\", random_forest)\n",
    "    xgb_model = xgb(x_train, x_test, y_train, y_test)\n",
    "    print(\"Extreme Gradient Boosting:\", xgb_model)\n",
    "#     ann_name = ann(x_train, x_test, y_train, y_test)\n",
    "#     print(\"ANN:\", ann_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    collection_pointer = ds.initialising_mongo()\n",
    "    complete_dataset = pd.DataFrame(list(collection_pointer.find()))\n",
    "    complete_dataset.dropna(inplace = True)\n",
    "    complete_dataset['merged'] = complete_dataset[\"title\"] + complete_dataset[\"url_path\"] + complete_dataset['comments'] + complete_dataset[\"content\"]\n",
    "    w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    \n",
    "    def lemmatize_text(text):\n",
    "        return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "    \n",
    "    complete_dataset[\"comments\"] = complete_dataset.comments.apply(lemmatize_text)\n",
    "    complete_dataset[\"title\"] = complete_dataset.title.apply(lemmatize_text)\n",
    "    complete_dataset[\"content\"] = complete_dataset.content.apply(lemmatize_text)\n",
    "    complete_dataset[\"url_path\"] = complete_dataset.url_path.apply(lemmatize_text)\n",
    "    \n",
    "\n",
    "\n",
    "#     print(complete_dataset.merged)\n",
    "    \n",
    "#     print(complete_dataset.flair.value_counts())\n",
    "#     complete_dataset = complete_dataset.astype({\"num_comments\": int, \"score\": int, \"timestamp\": float})\n",
    "    Y = complete_dataset.flair\n",
    "    x = complete_dataset.drop('flair', axis = 1)\n",
    "    \n",
    "#     print(\"comments as feature\")\n",
    "#     call_models(x.comments, Y)\n",
    "#     print(\"\\ntitle as a feature\")\n",
    "#     call_models(x.title, Y)\n",
    "#     print(\"\\ncontent as a feature\")\n",
    "#     call_models(x.content, Y)\n",
    "#     print(\"\\nurl_path as a feature\")\n",
    "#     call_models(x.url_path, Y)\n",
    "#     print(\"\\nurl_hostname as a feature\")\n",
    "#     call_models(x.url_hostname, Y)\n",
    "    print(\"\\nmerged as a feature\")\n",
    "    call_models(x.merged, Y)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "merged as a feature\n",
      "Extreme Gradient Boosting: 0.6376811594202898\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
